\subsection{Retraining del modello}
\fancyhead{}    % reset header
\fancyhead[R]{Retraining del modello}

Una volta inserite le nuove istanze al termine della compilazione del questionario, il modello deve essere \textbf{riallenato} considerando i nuovi valori inseriti.\vspace{1ex}
Per fare ciò è stato necessario creare un \textbf{modulo python} che contenesse un \textbf{interprete} e \textbf{un'ambiente virtuale} in grado di installare tutte le liberie necessarie per l'esecuzione di un file python \textcolor{gray!50!black}{\textit{(trainingModel.py)}} contenente il codice necessario per fare ciò. \\ 

\begin{lstlisting}[caption=Prelievo del dataset]
    # coding: utf-8
    import pandas as pd
    
    FILE_NAME = "../src/main/resources/ModuloAI/data.csv"
    
    # Verifica il contenuto del file
    try:
        df = pd.read_csv(FILE_NAME)
    except pd.errors.EmptyDataError:
        print("Il file CSV e' vuoto.")
    except pd.errors.ParserError:
        print("Errore di parsing del file CSV.")
    except Exception as e:
        print(e)
\end{lstlisting} 

In questa parte si va a prelevare il dataset presente in una cartella specifica del nostro progetto.
Tale dataset è stato estratto in formato \textbf{csv} e tramite il modulo \textbf{pandas} si andrà ad ottenere il \textbf{DataFrame} contente tutte le tuple del dataset.\vspace{1ex}\\
In caso di dataset vuoto viene ritornata un'eccezione (gestita dal metodo chiamante java) come succede anche per errori di \textbf{parsing} del file csv e per errori generici. \\

\begin{lstlisting}[caption=Feature preparation]
   from sklearn.ensemble import RandomForestRegressor
   from sklearn.preprocessing import RobustScaler
   from sklearn2pmml import sklearn2pmml
   from sklearn2pmml.pipeline import PMMLPipeline

   #Scelta variabile dipendente (y) e indipendenti (X)
   X=df.drop(columns=['Duration','VRHeadset',"UserID"])   #feature selection
   y=df.Duration

   # Adattamento e trasformazione dei dati con RobustScaler
   scaler = RobustScaler()
   X_scaled = scaler.fit_transform(X)

  # Creazione del modello di regressione con Random Forest
  model = RandomForestRegressor()
  model.fit(X_scaled, y)
\end{lstlisting} 

In quest altro blocco di codice si va a trasformare il dataset e i dati al suo interno per prepararli al \textbf{training} del modello. ( pragrafo \ref{paragrafo 3.1} per una descrizione più dettagliata). \vspace{1ex}\\ 
Dopo aver applicato il \textbf{metodo empirico} su vari algoritmi e per ogni algortimo aver applicato \textbf{3 tipologie di scaling} diverse, si è visto che l'algoritmo che si adatta meglio ai dati è il \textbf{RandomForestRegressor} applicando però la \textbf{RobustScaler} sui dati.
Per preparare i dati vi sono una serie di passi da seguire:
\par{
\begin{itemize}
   \item \textbf{feature selection}: vengono selezionate le feature \textbf{caratterizzanti} del problema in esame: \textit{Age, Gender, MotionSickness, ImmersionLevel}. Feature come \textit{VRHeadset} non sono state considerate in quanto i visori che verranno utilizzati nelle lezioni virtuali hanno headset diversi dalle 3 tipologie presenti nel dataset. In più, il regressore dovrà stimare la durata ideale di un meeting in una determinata stanza e per fare ciò si basa sul \textit{MotionSickess} che racchiude tutti i fastidi provati durante meeting precedenti, incluso anche quello dell'headset. 
   \item \textbf{feature scaling}: come detto prima, il \textbf{RobustScaler} consente di fare stime più accurate rispetto altri scaler. Da come si legge nel codice, viene applicato lo scaling su X che corrisponde all'insieme di tuple presenti nel dataset su cui è stata applicata la feature selection
   \item \textbf{feature balancing e feature cleaning}: non 
   sono stati applicati per i motivi descritti nel \textit{paragrafo \ref{paragrafo 3.1}}.
\end{itemize}
} \\ 

\begin{lstlisting}[caption=Conversione in un file PMML]
   # Creazione del PMMLPipeline con il modello già addestrato
   pipeline = PMMLPipeline([("Regression", model)])

   # Tentativo di estrazione del pipeline in un file PMML con gestione delle eccezioni
   try:
      sklearn2pmml(pipeline, "RegressoreDurataMeeting.pmml", with_repr=True)
   except Exception as e:
      print("Si è verificato un errore durante l'estrazione del pipeline in un file PMML:")
      print(e)
\end{lstlisting} 

In quest'ultima parte si andrà a convertire il modello già addestrato in un \textbf{file PMML} che verrà utilizzato per compiere stime in un altro modulo di MetaClass (descritto nel paragrafo \ref{paragrafo 5.1}). \vspace{1ex} \\
Per poter compiere la conversione è necessario creare una \textbf{pipeline} contenente il \textbf{modello addestrato}. l'istanza model inoltre conterrà anche tutti i dati del dataset con relativa separazione tra variabili dipendenti e indipendenti. \\
Infine in blocco try/except si creare il file che verrà salvato nella directory corrente del modulo python appena descritto.





